<!DOCTYPE HTML>
<!--
    Massively by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <title>Generalized Raking - Michal Palas</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link href="assets/css/prism.css" rel="stylesheet" /> 
        <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
    </head>
    <body class="is-preload">

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Header -->
                    <header id="header">
                        <a href="index.html" class="logo">My Portfolio</a>
                    </header>

                <!-- Nav -->
                <nav id="nav">
                    <ul class="links">
                        <li><a href="index.html">Homepage</a></li>
                        <li><a href="about.html">About me</a></li>
                        <li class="active"><a href="projects.html">Projects</a></li>
                    </ul>
                    <ul class="icons">
                        <li><a href="https://www.linkedin.com/in/michal-palas-26b37711a/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
                        <li><a href="https://github.com/palasmi" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
                    </ul>
                </nav>
                <!-- Main -->
                    <div id="main">

                        <!-- Post -->
                            <section class="post">
                                <header>
                                    <h1>Weighting survey data with generalized raking</h1>
                                        <ul class="icons">
                                        <li><a href="" class="button primary fit small">Python</a></li>
                                        <li><a target="_blank" href="https://github.com/palasmi/Weighting-survey-data-generalized-raking" class="icon brands fa-github"><span class="label">Github</span></a></li>
                                    </ul>
                                </header>
                                <p>Very often we need to weight a survey data to make them representative of population. 
                                Typically we try to match distributions of different characteristics observed in a population, such as age, gender, level of education, or income.
                                <i>Iterative Proportional Fitting</i> is often used to generate the weights. This method has, however, a drawback - it often
                                generates very unbalanced weights (meaning that some observations get very low and some very high weights). This problem is discussed
                                for example in <a target="_blank" href="https://dev.to/potloc/generalized-raking-for-survey-weighting-2d1d">this great article</a>.</p>
                                <p>The article suggests using a <i>Generalized Raking</i> algorithm that generates weights that are as close to 1 as possible. The trick is in 
                                utilizing a constrained optimization where we try to minimize a function of weights that has minimum in 1 while satisfying constraints that 
                                the weighted data have to match the target distributions. The mentioned article proposed a python implementation of this method as well. However
                                their approach might be very restrictive. Let me explain why: they use cross-dimensional weighting, which means that it would not be enough to define 
                                for example the distribution of levels of education and the distribution of age groups, but one would need to define frequency of all combinations of 
                                age and education. </p>
                                <span class="image fit">
                                    <img src="images/scale.jpg" alt="">
                                </span>
                                <p>Adding more characteristics, such as gender or region would mean a need of extremely detailed information (basically frequencies
                                for all the combinations of these four characteristics) that is often not known or at least hard to gather. Another problem arises, if we have no person
                                representing some of the combinations of characteristics (which is very likely to happen when combining multiple characteristics). 
                                In such case, the proposed algorithm does not work. In fact, for most of the projects with survey data, I have been using a weighting without crossing the characteristics - 
                                matching the distributions of main characteristics, such that in the end we have same distributions of men and women or people with university degree as
                                in population without caring about matching the weight of 79 years old women with bachelor degree. </p>
                                <p>Therefore I decided to implement a <i>Generalized Raking</i> algorithm for a weighting without crossing distributions in <i>python</i>. The following lines 
                                present the ideas behind the algorithm and show complete code.</p>
                                <p>Let's create a bunch of observations defined by two characteristics - age group and education level, and define target population distributions.</p>
                                <pre  class="no-line-numbers"><code class="language-python">import numpy as np
import math

# generating age (5 possible levels) and education level (4 levels) 50 observations
age = np.random.randint(0,5,50)
educ = np.random.randint(0,4,50)

# numpy array where one row = one observation, 
# every column representing one characteristic we use for weighting
to_weight = np.column_stack((age, educ))

# preparing array for the weights
weights = np.zeros(to_weight.shape[0])

# defining shares in population
age_pop = np.array([0.2, 0.25, 0.15, 0.3, 0.1])
educ_pop = np.array([0.25, 0.25, 0.4, 0.1])

# getting respective counts in the population of size of our survey sample (50 observations)
population = []
population.append(age_pop*to_weight.shape[0])
population.append(educ_pop*to_weight.shape[0])</code></pre>
                                <p>Now we have to define the function we will try to minimize. Remember, we want every single weight to be 
                                    as close to 1 as possible. Our optimization problem can be described with following formula:</p>
                                    <p align="center">    $ \underset{w}{arg\ min}\ F(w)\ s.t.\ X^Tw = T \\ F(x) = || ( x_1(log(x_1)-1) + 1 \ ,\  x_2(log(x_2)-1) + 1 \ ,\  ...)||$</p>
                                    <p>where $w$ is the vector of weights, $X$ is a matrix of 0's and 1's and size (number of respondents X number of possible target values) and $T$
                                    is distribution of these targets in the target population. Function $F$ is a simple linear norm of the vector, where every element of the vector
                                    is a function of one weight. This function ($x_i(log(x_i)-1) + 1$) has minimum equal to 0 in 1. Minimizing a linear norm of the vector 
                                    corresponds to pushing its elements close to 0, which corresponds to pushing the individual weights to 1. The nummerical optimizer we will
                                     use requires us to minimize a single value. That requirement is satisfied because we minimize the linear norm (and not the vector elements separately).</p>
                                    <p> Note that we wrote just one binding constraint but generally we have
                                as many constraints as we have characteristics we try to match. In our case we would have one constraint for age and one for education (for simplicity
                                 we don't use tensor algebra here).</p>
                                 <p>When defining the functions in <i>python</i>, we use
                                <i><a href="https://numba.pydata.org/">Numba</a></i>, which translates the function to the machine code and thus
                                improves the overall performance (with survey samples of hundreds observations we are running millions of operations
                                and thus even small improvements in performance can make a big difference, same as a parallelization of some operations).</p>
                                <pre  class="no-line-numbers"><code class="language-python">from numba import njit

@njit(fastmath=True)
def fast_fun(x):
    s = 0.
    for i in range(x.shape[0]):
        s+=(x[i]*(math.log(x[i])-1) + 1 )**2

    return math.sqrt(s)</code></pre>
                                <p>Note that instead of using the predefined <i>numpy</i> method for linear norm, we calculate it ourselves using functions from math module, which turned out 
                                    to be a bit faster solution during our testing. Similarly we define the function for our constraints.
                                </p>
                                <pre  class="no-line-numbers"><code class="language-python"># in this case Numba can parallelize some of the operations
@njit(fastmath=True, parallel=True)
def fast_constr(w,x,b):
    c = np.dot(x.T,w)-b
    s = 0.
    for i in range(c.shape[0]):
        s+=(c[i])**2
        
    return math.sqrt(s)        </code></pre>
                                <p>Now we just need a python function that will run numerical solver and generates weights for us. Note that <i>scipy</i> package in version 1.5
                                    might raise an error during the optimization. Use either version 1.4.1 or versions newer than 1.5.
                                </p>
                                <pre  class="no-line-numbers"><code class="language-python">from scipy.optimize import minimize

def gen_raking(data_classes, pop_shares, ftol=1e-2, maxiter=500, eps=1e-8, verbose=False):
    """Function generating sample weights (typically for survey data) using generalized 
    raking to match the population shares for multiple characteristics. Shares are matched
    independently and not as crossproducts. As opposed to Iterative Proportional Fitting, 
    the constrained optimization problem is solved, where the objective is to generate weights
    as close to 1 as possible: minimizing w(log(w) - 1) + 1, as suggested in Deville et al. (1992)
     to avoid having samples with very high/low weights.

    Args:
        data_classes (numpy.ndarray): Array of shape n x k, where n is number of samples and 
                                    k number of characteristics we use to match the population
                                    distribution. The i-th row represents the numbers of groups the i-th
                                    sample is member of. All the individual characteristics in the 
                                    population need to be represented by some sample in the data.
        pop_shares (list): list of length k (number of characteristics used to match the population) 
                            containing lists. Every individual list contains shares of the allowed 
                            values of the individual characteristic in the target population.

        ftol (float): Precision goal for the value of f in the stopping criterion.
        maxiter (int): Maximum number of iterations for the optimization algorithm.
        eps (float): Step size used for numerical approximation of the Jacobian.
        verbose (bool): whether to print the target distributions and distributions of weighted data.


    Returns:
        _type_: _description_
    """

    # we want to check that we have all and only the target groups represented in the data
    for i in range(data_classes.shape[1]):
        if set(np.unique(data_classes[:,i])) != set(range(len(pop_shares[i]))):
            raise ValueError("""Characteristics in the data do not match the population 
            characteristics. Either one group not present in the data or too many groups 
            present (characteristic: {})".format(i+1)""")

    # adjust shares to actual counts of samples we want to have in every group
    for i in range(data_classes.shape[1]):
        pop_shares[i] = pop_shares[i]*data_classes.shape[0]/pop_shares[i].sum()

    # characteristics of the data must be recoded into dummies, separate array for every variable
    types = []
    for i in range(data_classes.shape[1]):
        values = data_classes[:,i].astype("int")
        n_values = np.max(values) + 1
        types.append(np.eye(n_values)[values])


    # optimization constrains in the form X'W = b. ie weighted samples need to represent defined population
    cons = []
    for i in range(data_classes.shape[1]):
        cons.append({"type":"eq", "fun": lambda w, x = types[i], 
                    b = pop_shares[i] : fast_constr(w,x,b)})

    # initial weights - let's start with naive 1's
    x0 = np.ones(data_classes.shape[0])
    # bounds for our weights - we don't want 0 or negative weights
    b = [(0.001,None)]*data_classes.shape[0]
    
    # 1.5 Version of scipy throws error here. It should work with 1.4.1 or with new versions
    res = minimize(fast_fun, x0 = x0, constraints=cons, bounds = b, method='SLSQP', 
                    options=dict(ftol=ftol, maxiter=maxiter, eps=eps, disp=False) ) 

    weights = res.x

    if verbose:
        print("Comparison of target and shares in weighted data:")
        for i in range(data_classes.shape[1]):
            print("Target {}".format(i))
            print(pop_shares[i])
            print("Weighted data:")
            print(np.dot(types[i].T,weights))


    return weights</code></pre>
                                    <p>Last step is to weight our data:</p>
                                    <pre  class="no-line-numbers"><code class="language-python">weights = gen_raking(to_weight, population, ftol=0.001, maxiter=500, eps=1e-8, verbose=True)</code></pre>
<p>We get:</p>
<pre><code class="language-none">Comparison of target and shares in weighted data:
Target 0
[10.  12.5  7.5 15.   5. ]
Weighted data:
[10.00010403 12.49980391  7.50010186 14.99964369  5.00012065]
Target 1
[12.5 12.5 20.   5. ]
Weighted data:
[12.49980383 12.50036659 19.99977207  4.99983165]</code></pre>
<p>As one can see, we were able to match the target distributions pretty accuratelly. Our individual weights are:</p>
    <pre><code class="language-none">>>> weights
array([1.50754192, 0.70123665, 0.4956768 , 1.06891711, 0.45889284,
       0.37444273, 0.05760291, 0.49567691, 1.50754192, 0.0567302 ,
       0.05135378, 1.50754186, 1.50754171, 0.05672855, 4.03277177,
       1.06891698, 4.0327717 , 0.70123674, 0.0576026 , 1.5075417 ,
       0.47344898, 0.70123639, 0.45889285, 1.69883686, 0.05760335,
       0.69571992, 0.473449  , 0.05135325, 1.06891722, 0.49567686,
       3.45455301, 4.03277182, 0.69571971, 0.37444275, 0.0513535 ,
       0.7012365 , 1.06891707, 0.47344908, 1.06891723, 0.69572005,
       0.37444267, 1.50754178, 1.69883684, 0.47344906, 0.05672965,
       2.9013284 , 0.05672949, 1.6988368 , 0.49567683, 0.69571983])    </code></pre>
    <p>I hope you will find the algorithm helpful for some of your projects. Feel free to download the full code
    from <a target="_blank" href="https://github.com/palasmi/Weighting-survey-data-generalized-raking">Github</a>. </p>
    <p>Note: The optimizer can get pretty slow with bigger samples (~ over 1000) and multiple characteristics to match.
   In such cases, we recommend to split the sample into balanced subsamples, weight them separately, and then
    average the weights for respondents with same characteristics.</p>
    <p>Image source: Unsplash</p>

                            </section>

                    </div>

                <!-- Footer -->
                <!-- Footer -->
                <footer id="footer">
                    <!-- <section> -->
                        <!-- <form method="post" action="#">
                            <div class="fields">
                                <div class="field">
                                    <label for="name">Name</label>
                                    <input type="text" name="name" id="name" />
                                </div>
                                <div class="field">
                                    <label for="email">Email</label>
                                    <input type="text" name="email" id="email" />
                                </div>
                                <div class="field">
                                    <label for="message">Message</label>
                                    <textarea name="message" id="message" rows="3"></textarea>
                                </div>
                            </div>
                            <ul class="actions">
                                <li><input type="submit" value="Send Message" /></li>
                            </ul>
                        </form>
                    </section> -->
                    <section class="split contact">
                        <!-- <section class="alt">
                            <h3>Address</h3>
                            <p>1234 Somewhere Road #87257<br />
                            Nashville, TN 00000-0000</p>
                        </section>
                        <section>
                            <h3>Phone</h3>
                            <p><a href="#">(000) 000-0000</a></p>
                        </section> -->
                        <section>
                            <h3>Email</h3>
                            <p><a href="mailto:palas.michal@gmail.com">palas.michal@gmail.com</a></p>
                        </section>
                        <!-- <section>
                            <h3>Social</h3>
                            <ul class="icons alt">
                                <li><a href="#" class="icon brands alt fa-linkedin"><span class="label">Twitter</span></a></li>
                                <li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                            </ul>
                        </section> -->
                    </section>
                    <section class="split contact">
                        <!-- <section class="alt">
                            <h3>Address</h3>
                            <p>1234 Somewhere Road #87257<br />
                            Nashville, TN 00000-0000</p>
                        </section>
                        <section>
                            <h3>Phone</h3>
                            <p><a href="#">(000) 000-0000</a></p>
                        </section>
                        <section>
                            <h3>Email</h3>
                            <p><a href="#">info@untitled.tld</a></p>
                        </section> -->
                        <section>
                            <h3>Social</h3>
                            <ul class="icons alt">
                                <li><a href="https://www.linkedin.com/in/michal-palas-26b37711a/" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
                                <li><a href="https://github.com/palasmi" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                            </ul>
                        </section>
                    </section>
                </footer>

            <!-- Copyright -->
                <div id="copyright">
                    <ul><li>&copy; Michal Palas 2022</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
                </div>

        </div>

        <!-- Scripts -->
            <script src="assets/js/jquery.min.js"></script>
            <script src="assets/js/jquery.scrollex.min.js"></script>
            <script src="assets/js/jquery.scrolly.min.js"></script>
            <script src="assets/js/browser.min.js"></script>
            <script src="assets/js/breakpoints.min.js"></script>
            <script src="assets/js/util.js"></script>
            <script src="assets/js/main.js"></script>
            <script src="assets/js/prism.js"></script> 
            <script type="text/x-mathjax-config">
                MathJax.Hub.Config({
                  jax: ["input/TeX", "output/HTML-CSS"],
                  extensions: ["tex2jax.js"],
                  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
                  tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
                  TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
                  messageStyle: "none"
                });
                </script>    
                <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script>
    </body>
</html>